{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaeyh4/pm2.5/blob/main/final_aispark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvCYspS09wmH",
        "outputId": "58c25e64-4de9-4571-a572-d988a44e7282"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.10/dist-packages (0.0.post5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.8)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install numpy pandas tensorflow keras sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQbgy-XK6hJp",
        "outputId": "a6409e75-f909-40a1-c32b-32362eaa3a44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   연도           일시   지점  PM2.5              관측시점         위도          경도  \\\n",
            "0   0  01-01 00:00  성성동  0.044  2000-01-01 00:00  36.840313  127.141777   \n",
            "1   0  01-01 00:00  신방동  0.056  2000-01-01 00:00  36.782355  127.120506   \n",
            "2   0  01-01 01:00  성성동  0.040  2000-01-01 01:00  36.840313  127.141777   \n",
            "3   0  01-01 01:00  신방동  0.048  2000-01-01 01:00  36.782355  127.120506   \n",
            "4   0  01-01 02:00  성성동  0.048  2000-01-01 02:00  36.840313  127.141777   \n",
            "\n",
            "  nearest_aws_지점    기온(°C)  풍향(deg)   풍속(m/s)  강수량(mm)  습도(%)  \\\n",
            "0             성거  0.157978   0.0125  0.012788      0.0  0.615   \n",
            "1             성거  0.157978   0.0125  0.012788      0.0  0.615   \n",
            "2             성거  0.153239   0.0000  0.007673      0.0  0.593   \n",
            "3             성거  0.153239   0.0000  0.007673      0.0  0.593   \n",
            "4             성거  0.137441   0.0000  0.010230      0.0  0.674   \n",
            "\n",
            "           관측시점_aws  \n",
            "0  2000-01-01 00:00  \n",
            "1  2000-01-01 00:00  \n",
            "2  2000-01-01 01:00  \n",
            "3  2000-01-01 01:00  \n",
            "4  2000-01-01 02:00  \n",
            "   지점_pm      위도_pm       경도_pm nearest_aws_지점 지점_aws   위도_aws    경도_aws\n",
            "0    성성동  36.840313  127.141777             성거     성거  36.8782  127.1561\n",
            "1    신방동  36.782355  127.120506             성거     성거  36.8782  127.1561\n",
            "2    아름동  36.512252  127.246789           세종고운   세종고운  36.5315  127.2406\n",
            "3    문창동  36.317215  127.437825            오월드    오월드  36.2913  127.3959\n",
            "4    정림동  36.304442  127.366742            오월드    오월드  36.2913  127.3959\n",
            "5    독곶리  36.987579  126.391672             대산     대산  37.0106  126.3881\n",
            "6    예산군  36.677398  126.848918             예산     예산  36.7421  126.8144\n",
            "7    신흥동  36.592887  127.292550           세종연서   세종연서  36.5667  127.2806\n",
            "8     공주  36.446951  127.119209             공주     공주  36.4828  127.1365\n",
            "9    읍내동  36.372388  127.417714             장동     장동  36.4135  127.4382\n",
            "10   동문동  36.780158  126.455197             태안     태안  36.7585  126.2964\n",
            "11   이원면  36.869719  126.280501             태안     태안  36.7585  126.2964\n",
            "12    논산  36.199217  127.087021             논산     논산  36.2116  127.1082\n",
            "13   모종동  36.782700  127.014610             아산     아산  36.8458  126.8654\n",
            "14  대천2동  36.353148  126.589735            대천항    대천항  36.3244  126.5021\n",
            "15   노은동  36.368242  127.318498             계룡     계룡  36.3132  127.2407\n",
            "16   홍성읍  36.597673  126.655087             홍북     홍북  36.6277  126.6451\n",
            "   연도           일시   지점  PM2.5              관측시점         위도          경도  \\\n",
            "0   4  01-01 00:00  성성동  0.084  2004-01-01 00:00  36.840313  127.141777   \n",
            "1   4  01-01 00:00  신방동  0.068  2004-01-01 00:00  36.782355  127.120506   \n",
            "2   4  01-01 01:00  성성동  0.068  2004-01-01 01:00  36.840313  127.141777   \n",
            "3   4  01-01 01:00  신방동  0.076  2004-01-01 01:00  36.782355  127.120506   \n",
            "4   4  01-01 02:00  성성동  0.052  2004-01-01 02:00  36.840313  127.141777   \n",
            "\n",
            "  nearest_aws_지점    기온(°C)   풍향(deg)   풍속(m/s)  강수량(mm)  습도(%)  \\\n",
            "0             성거  0.225908  0.051667  0.025575      0.0  0.548   \n",
            "1             성거  0.225908  0.051667  0.025575      0.0  0.548   \n",
            "2             성거  0.218009  0.000000  0.005115      0.0  0.570   \n",
            "3             성거  0.218009  0.000000  0.005115      0.0  0.570   \n",
            "4             성거  0.206951  0.000000  0.005115      0.0  0.631   \n",
            "\n",
            "           관측시점_aws  \n",
            "0  2004-01-01 00:00  \n",
            "1  2004-01-01 00:00  \n",
            "2  2004-01-01 01:00  \n",
            "3  2004-01-01 01:00  \n",
            "4  2004-01-01 02:00  \n",
            "         지점  PM2.5              관측시점    기온(°C)   풍향(deg)   풍속(m/s)  강수량(mm)  \\\n",
            "61824    공주  0.060  2004-01-01 00:00  0.244866  0.123333  0.038363      0.0   \n",
            "61825    공주  0.064  2004-01-01 01:00  0.232227  0.167778  0.033248      0.0   \n",
            "61826    공주  0.072  2004-01-01 02:00  0.206951  0.000000  0.002558      0.0   \n",
            "61827    공주  0.064  2004-01-01 03:00  0.199052  0.000000  0.002558      0.0   \n",
            "61828    공주  0.056  2004-01-01 04:00  0.189573  0.000000  0.002558      0.0   \n",
            "...     ...    ...               ...       ...       ...       ...      ...   \n",
            "131371  홍성읍  0.056  2004-11-18 19:00  0.404423  0.833611  0.089514      0.0   \n",
            "131372  홍성읍  0.036  2004-11-18 20:00  0.396524  0.830556  0.074169      0.0   \n",
            "131373  홍성읍  0.020  2004-11-18 21:00  0.393365  0.837500  0.084399      0.0   \n",
            "131374  홍성읍  0.024  2004-11-18 22:00  0.387046  0.806944  0.094629      0.0   \n",
            "131375  홍성읍  0.024  2004-11-18 23:00  0.366509  0.848889  0.066496      0.0   \n",
            "\n",
            "        습도(%)  \n",
            "61824   0.647  \n",
            "61825   0.648  \n",
            "61826   0.734  \n",
            "61827   0.753  \n",
            "61828   0.795  \n",
            "...       ...  \n",
            "131371  0.554  \n",
            "131372  0.552  \n",
            "131373  0.579  \n",
            "131374  0.593  \n",
            "131375  0.622  \n",
            "\n",
            "[131376 rows x 8 columns]\n",
            "1047/1047 [==============================] - 4s 3ms/step\n",
            "210/210 [==============================] - 1s 3ms/step\n",
            "Location: 공주, Train MAE: 0.04820051963246424, Validation MAE: 0.04408753518868978\n",
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-227e6112a2d4>:324: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  all_test_data_real = all_test_data_real.append(test_data_loc_real_df, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1031/1031 [==============================] - 4s 3ms/step\n",
            "206/206 [==============================] - 1s 3ms/step\n",
            "Location: 노은동, Train MAE: 0.044847634316269605, Validation MAE: 0.0370035892359741\n",
            "2/2 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-227e6112a2d4>:324: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  all_test_data_real = all_test_data_real.append(test_data_loc_real_df, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1041/1041 [==============================] - 4s 3ms/step\n",
            "208/208 [==============================] - 1s 3ms/step\n",
            "Location: 논산, Train MAE: 0.04885205323552174, Validation MAE: 0.04754688417266836\n",
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-227e6112a2d4>:324: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  all_test_data_real = all_test_data_real.append(test_data_loc_real_df, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1056/1056 [==============================] - 4s 3ms/step\n",
            "212/212 [==============================] - 1s 3ms/step\n",
            "Location: 대천2동, Train MAE: 0.040770241772800184, Validation MAE: 0.0361822654639217\n",
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-227e6112a2d4>:324: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  all_test_data_real = all_test_data_real.append(test_data_loc_real_df, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1028/1028 [==============================] - 4s 3ms/step\n",
            "206/206 [==============================] - 1s 3ms/step\n",
            "Location: 독곶리, Train MAE: 0.048015610494378747, Validation MAE: 0.04863198787454626\n",
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-227e6112a2d4>:324: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  all_test_data_real = all_test_data_real.append(test_data_loc_real_df, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "998/998 [==============================] - 4s 3ms/step\n",
            "200/200 [==============================] - 1s 4ms/step\n",
            "Location: 동문동, Train MAE: 0.06268278891279883, Validation MAE: 0.05950434139186403\n",
            "2/2 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-227e6112a2d4>:324: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  all_test_data_real = all_test_data_real.append(test_data_loc_real_df, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1045/1045 [==============================] - 4s 3ms/step\n",
            "209/209 [==============================] - 1s 3ms/step\n",
            "Location: 모종동, Train MAE: 0.050315636599685395, Validation MAE: 0.04298238696920527\n",
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-227e6112a2d4>:324: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  all_test_data_real = all_test_data_real.append(test_data_loc_real_df, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1058/1058 [==============================] - 4s 3ms/step\n",
            "212/212 [==============================] - 1s 3ms/step\n",
            "Location: 문창동, Train MAE: 0.05042252858204989, Validation MAE: 0.04542092900876001\n",
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-227e6112a2d4>:324: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  all_test_data_real = all_test_data_real.append(test_data_loc_real_df, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1053/1053 [==============================] - 4s 3ms/step\n",
            "211/211 [==============================] - 1s 3ms/step\n",
            "Location: 성성동, Train MAE: 0.05246611840248647, Validation MAE: 0.04579263800384408\n",
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-227e6112a2d4>:324: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  all_test_data_real = all_test_data_real.append(test_data_loc_real_df, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1072/1072 [==============================] - 4s 3ms/step\n",
            "215/215 [==============================] - 1s 3ms/step\n",
            "Location: 신방동, Train MAE: 0.05412545166065963, Validation MAE: 0.05207166030335147\n",
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-227e6112a2d4>:324: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  all_test_data_real = all_test_data_real.append(test_data_loc_real_df, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1054/1054 [==============================] - 4s 3ms/step\n",
            "211/211 [==============================] - 1s 4ms/step\n",
            "Location: 신흥동, Train MAE: 0.05215642230614646, Validation MAE: 0.04553993813951794\n",
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-227e6112a2d4>:324: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  all_test_data_real = all_test_data_real.append(test_data_loc_real_df, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1059/1059 [==============================] - 4s 3ms/step\n",
            "212/212 [==============================] - 1s 4ms/step\n",
            "Location: 아름동, Train MAE: 0.05202193633769045, Validation MAE: 0.045002766855709975\n",
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-227e6112a2d4>:324: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  all_test_data_real = all_test_data_real.append(test_data_loc_real_df, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1056/1056 [==============================] - 4s 3ms/step\n",
            "212/212 [==============================] - 1s 3ms/step\n",
            "Location: 예산군, Train MAE: 0.049536735295083074, Validation MAE: 0.042253870637979155\n",
            "2/2 [==============================] - 0s 9ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-227e6112a2d4>:324: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  all_test_data_real = all_test_data_real.append(test_data_loc_real_df, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1039/1039 [==============================] - 4s 3ms/step\n",
            "208/208 [==============================] - 1s 3ms/step\n",
            "Location: 읍내동, Train MAE: 0.05952180417946679, Validation MAE: 0.04865661616762497\n",
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-227e6112a2d4>:324: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  all_test_data_real = all_test_data_real.append(test_data_loc_real_df, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1035/1035 [==============================] - 4s 3ms/step\n",
            "207/207 [==============================] - 1s 3ms/step\n",
            "Location: 이원면, Train MAE: 0.04213614932080116, Validation MAE: 0.044276312290529383\n",
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-227e6112a2d4>:324: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  all_test_data_real = all_test_data_real.append(test_data_loc_real_df, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1057/1057 [==============================] - 4s 3ms/step\n",
            "212/212 [==============================] - 1s 3ms/step\n",
            "Location: 정림동, Train MAE: 0.03822587576787157, Validation MAE: 0.03670023140409362\n",
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-227e6112a2d4>:324: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  all_test_data_real = all_test_data_real.append(test_data_loc_real_df, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1046/1046 [==============================] - 4s 3ms/step\n",
            "210/210 [==============================] - 1s 3ms/step\n",
            "Location: 홍성읍, Train MAE: 0.05638572589351701, Validation MAE: 0.04557658969243472\n",
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-227e6112a2d4>:324: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  all_test_data_real = all_test_data_real.append(test_data_loc_real_df, ignore_index=True)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "from pandas._libs.tslibs import tz_convert_from_utc_single\n",
        "\n",
        "os.chdir('/content/awsdata')\n",
        "all_files = glob.glob('*.csv')\n",
        "dfs = []\n",
        "for file in all_files:\n",
        "    df = pd.read_csv(file)\n",
        "    dfs.append(df)\n",
        "\n",
        "aws_data = pd.concat(dfs, ignore_index=True)\n",
        "aws_data.to_csv('/content/new/combined_aws_data.csv', index=False)\n",
        "\n",
        "os.chdir('/content/pmdata')  \n",
        "my_files = glob.glob('*.csv')\n",
        "dfss = []\n",
        "for file in my_files:\n",
        "    dfp = pd.read_csv(file)\n",
        "    dfss.append(dfp)\n",
        "\n",
        "pm_data = pd.concat(dfss, ignore_index=True)\n",
        "pm_data.to_csv('/content/new/combined_pm_data.csv', index=False)\n",
        "\n",
        "\n",
        "new_column = {'측정소' : '지점'}\n",
        "pm_data = pm_data.rename(columns= new_column)\n",
        "\n",
        "os.chdir('/content/aws station')\n",
        "aws_stations = pd.read_csv('awsmap.csv')\n",
        "\n",
        "os.chdir('/content/pm station')\n",
        "pm_stations = pd.read_csv('pmmap.csv')\n",
        "\n",
        "drop_pm_stat = ['Description']\n",
        "pm_stations = pm_stations.drop(columns=drop_pm_stat, axis = 1)\n",
        "new_column = {'Location' : '지점',\n",
        "              'Latitude' : '위도',\n",
        "              'Longitude' : '경도'}\n",
        "pm_stations = pm_stations.rename(columns= new_column)\n",
        "\n",
        "drop_aws_stat = ['Description']\n",
        "aws_stations = aws_stations.drop(columns=drop_aws_stat, axis = 1)\n",
        "new_column = {'Location' : '지점',\n",
        "              'Latitude' : '위도',\n",
        "              'Longitude' : '경도'}\n",
        "aws_stations = aws_stations.rename(columns= new_column)\n",
        "\n",
        "def convert_year(year):\n",
        "    return str(2000 + int(year))\n",
        "\n",
        "pm_data['관측시점'] = pm_data['연도'].apply(convert_year) + '-' + pm_data['일시']\n",
        "aws_data['관측시점'] = aws_data['연도'].apply(convert_year) + '-' + aws_data['일시']\n",
        "\n",
        "pm_data = pm_data.merge(pm_stations, on='지점', how='left')\n",
        "aws_data = aws_data.merge(aws_stations, on='지점', how='left')\n",
        "\n",
        "pm_data.head(5)\n",
        "\n",
        "# Remove rows with any null values in pm_data\n",
        "clean_pm_data = pm_data.dropna()\n",
        "clean_pm_data.to_csv('/content/clean_combined_pm_data.csv', index=False)\n",
        "\n",
        "# Remove rows with any null values in aws_data\n",
        "clean_aws_data = aws_data.dropna()\n",
        "clean_aws_data.to_csv('/content/clean_combined_aws_data.csv', index=False)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Extract unique locations and coordinates for both datasets\n",
        "pm_locations = clean_pm_data[['지점', '위도', '경도']].drop_duplicates()\n",
        "aws_locations = clean_aws_data[['지점', '위도', '경도']].drop_duplicates()\n",
        "\n",
        "# Find the nearest AWS location for each PM location using NearestNeighbors\n",
        "nearest_neighbors = NearestNeighbors(n_neighbors=1)\n",
        "nearest_neighbors.fit(aws_locations[['위도', '경도']].values)\n",
        "\n",
        "distances, indices = nearest_neighbors.kneighbors(pm_locations[['위도', '경도']].values)\n",
        "\n",
        "# Map the nearest AWS location to the corresponding PM location\n",
        "pm_locations['nearest_aws_지점'] = aws_locations.iloc[indices.flatten()]['지점'].values\n",
        "\n",
        "# Merge the PM data with the nearest AWS data\n",
        "merged_data = clean_pm_data.merge(pm_locations[['지점', 'nearest_aws_지점']], on='지점')\n",
        "merged_data = merged_data.merge(clean_aws_data, left_on=['nearest_aws_지점', '연도', '일시'], right_on=['지점', '연도', '일시'], suffixes=('', '_aws'))\n",
        "\n",
        "# Drop unnecessary columns from the merged DataFrame\n",
        "merged_data.drop(['지점_aws', '위도_aws', '경도_aws'], axis=1, inplace=True)\n",
        "\n",
        "print(merged_data.head())\n",
        "\n",
        "# Create a new DataFrame to store the PM location, its coordinates,\n",
        "# the nearest AWS location, and the coordinates of the nearest AWS location\n",
        "location_mapping = pm_locations[['지점', '위도', '경도']].copy()\n",
        "location_mapping['nearest_aws_지점'] = pm_locations['nearest_aws_지점']\n",
        "\n",
        "# Merge the coordinates of the nearest AWS locations\n",
        "location_mapping = location_mapping.merge(\n",
        "    aws_locations[['지점', '위도', '경도']],\n",
        "    left_on='nearest_aws_지점',\n",
        "    right_on='지점',\n",
        "    suffixes=('_pm', '_aws')\n",
        ")\n",
        "\n",
        "# Rename the columns for clarity\n",
        "location_mapping.columns = [\n",
        "    '지점_pm', '위도_pm', '경도_pm',\n",
        "    'nearest_aws_지점', '지점_aws', '위도_aws', '경도_aws'\n",
        "]\n",
        "\n",
        "print(location_mapping)\n",
        "\n",
        "df = merged_data.drop(columns=['관측시점_aws', '위도', '경도', '연도', '일시'])\n",
        "\n",
        "def reorder_columns(df, col_name):\n",
        "    cols = df.columns.tolist()\n",
        "    cols.remove(col_name)\n",
        "    cols.append(col_name)\n",
        "    return df[cols]\n",
        "\n",
        "df = reorder_columns(df, 'nearest_aws_지점')\n",
        "df = merged_data.drop(columns=['nearest_aws_지점'])\n",
        "\n",
        "# Sort the DataFrame by 'year-date-time' and 'location' columns\n",
        "sorted_data = df.sort_values(by=['지점','관측시점'])\n",
        "sorted_data = sorted_data.drop(columns=['관측시점_aws', '위도', '경도', '연도', '일시'])\n",
        "# Display the sorted DataFrame\n",
        "sorted_data.head(100)\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "\n",
        "def fill_missing_values(df):\n",
        "    first_valid_value = df['지점'].first_valid_index()\n",
        "    if first_valid_value is not None:\n",
        "        df['지점'] = df['지점'].fillna(df.loc[first_valid_value, '지점'])\n",
        "    return df\n",
        "\n",
        "os.chdir('/content/aws_test')\n",
        "all_files = glob.glob('*.csv')\n",
        "dft = []\n",
        "for file in all_files:\n",
        "    dfk = pd.read_csv(file)\n",
        "    dfk_filled = fill_missing_values(dfk)\n",
        "    dft.append(dfk_filled)\n",
        "\n",
        "aws_test = pd.concat(dft, ignore_index=True)\n",
        "\n",
        "os.chdir('/content/pm_test')\n",
        "my_files = glob.glob('*.csv')\n",
        "dftt = []\n",
        "for file in my_files:\n",
        "    dfl = pd.read_csv(file)\n",
        "    dftt.append(dfl)\n",
        "\n",
        "pm_test = pd.concat(dftt, ignore_index=True)\n",
        "\n",
        "new_column = {'측정소' : '지점'}\n",
        "pm_test = pm_test.rename(columns= new_column)\n",
        "\n",
        "def convert_year(year):\n",
        "    return str(2000 + int(year))\n",
        "\n",
        "pm_test['관측시점'] = pm_test['연도'].apply(convert_year) + '-' + pm_test['일시']\n",
        "aws_test['관측시점'] = aws_test['연도'].apply(convert_year) + '-' + aws_test['일시']\n",
        "\n",
        "pm_test = pm_test.merge(pm_stations, on='지점', how='left')\n",
        "aws_test = aws_test.merge(aws_stations, on='지점', how='left')\n",
        "\n",
        "aws_test.head(100)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "\n",
        "pmtest_locations = pm_test[['지점', '위도', '경도']].drop_duplicates()\n",
        "awstest_locations = aws_test[['지점', '위도', '경도']].drop_duplicates()\n",
        "\n",
        "# Find the nearest AWS location for each PM location using NearestNeighbors\n",
        "nearest_neighbors = NearestNeighbors(n_neighbors=1)\n",
        "nearest_neighbors.fit(awstest_locations[['위도', '경도']].values)\n",
        "\n",
        "distances, indices = nearest_neighbors.kneighbors(pmtest_locations[['위도', '경도']].values)\n",
        "\n",
        "# Map the nearest AWS location to the corresponding PM location\n",
        "pmtest_locations['nearest_aws_지점'] = awstest_locations.iloc[indices.flatten()]['지점'].values\n",
        "\n",
        "# Merge the PM data with the nearest AWS data\n",
        "merge_data = pm_test.merge(pmtest_locations[['지점', 'nearest_aws_지점']], on='지점')\n",
        "merge_data = merge_data.merge(aws_test, left_on=['nearest_aws_지점', '연도', '일시'], right_on=['지점', '연도', '일시'], suffixes=('', '_aws'))\n",
        "\n",
        "# Drop unnecessary columns from the merged DataFrame\n",
        "merge_data.drop(['지점_aws', '위도_aws', '경도_aws'], axis=1, inplace=True)\n",
        "\n",
        "print(merge_data.head())\n",
        "\n",
        "dff = merge_data.drop(columns=['관측시점_aws', '위도', '경도', '연도', '일시'])\n",
        "dff = merge_data.drop(columns=['nearest_aws_지점'])\n",
        "\n",
        "sort_data = dff.sort_values(by=['지점','관측시점'])\n",
        "sort_data = sort_data.drop(columns=['관측시점_aws', '위도', '경도', '연도', '일시'])\n",
        "sort_data.head(2000)\n",
        "print(sort_data)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from tensorflow.keras.regularizers import L1L2\n",
        "import tensorflow as tf\n",
        "\n",
        "np.random.seed(70)\n",
        "tf.random.set_seed(70)\n",
        "\n",
        "def has_missing_values(array):\n",
        "    return np.isnan(array).any()\n",
        "\n",
        "def prepare_data(data, lookback, future):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(data) - lookback - future):\n",
        "        X.append(data[i : (i + lookback), :])\n",
        "        Y.append(data[(i + lookback) : (i + lookback + future), 0])  \n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "def prepare_data_with_missing(data, lookback, future):\n",
        "    X, Y, missing_indices = [], [], []\n",
        "    for i in range(len(data) - lookback - future):\n",
        "        input_sequence = data[i : (i + lookback), :]\n",
        "        output_sequence = data[(i + lookback) : (i + lookback + future), 0]\n",
        "\n",
        "        if has_missing_values(input_sequence):\n",
        "            continue\n",
        "\n",
        "        X.append(input_sequence)\n",
        "\n",
        "        if has_missing_values(output_sequence):\n",
        "            missing_indices.append(i)\n",
        "        else:\n",
        "            Y.append(output_sequence)\n",
        "\n",
        "    return np.array(X), np.array(Y), missing_indices\n",
        "\n",
        "lookback = 2 * 24  # 2 days of hourly data\n",
        "future = 3 * 24    # 3 days of hourly data\n",
        "n_features = 6     # Number of features in the data\n",
        "\n",
        "\n",
        "locations = ['공주', '노은동', '논산', '대천2동', '독곶리', '동문동', '모종동', '문창동', '성성동', '신방동', '신흥동', '아름동', '예산군', '읍내동', '이원면', '정림동', '홍성읍']  # List all 17 locations\n",
        "#locations = ['공주']\n",
        "\n",
        "all_test_data_real = pd.DataFrame()\n",
        "\n",
        "for location in locations:\n",
        "    train_data_loc = sorted_data[sorted_data['지점'] == location]\n",
        "    test_data_loc = sort_data[sort_data['지점'] == location]\n",
        "    \n",
        "    # Drop the '지점' and '관측시점' columns\n",
        "    train_data_loc = train_data_loc.drop(['지점', '관측시점'], axis=1).values\n",
        "    test_data_loc = test_data_loc.drop(['지점', '관측시점'], axis=1).values\n",
        "    \n",
        "    # Scale the data\n",
        "    scaler = MinMaxScaler()\n",
        "    train_data_loc = scaler.fit_transform(train_data_loc)\n",
        "    test_data_loc = scaler.transform(test_data_loc)\n",
        "\n",
        "    # Prepare the data for LSTM\n",
        "    X_train, Y_train = prepare_data(train_data_loc, lookback, future)\n",
        "    X_test, Y_test, missing_indices = prepare_data_with_missing(test_data_loc, lookback, future)\n",
        "    \n",
        "    # Create the LSTM model\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(256, activation='tanh', input_shape=(lookback, n_features), return_sequences=True))\n",
        "    model.add(Dropout(0.2))  # Add dropout with a dropout rate of 0.2\n",
        "    model.add(LSTM(256, activation='tanh'))\n",
        "    model.add(Dropout(0.2))  # Add dropout with a dropout rate of 0.2\n",
        "    model.add(Dense(future))\n",
        "    model.compile(optimizer='adam', loss='mae')\n",
        "\n",
        "    # Add EarlyStopping callback\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    # Train the model with validation split\n",
        "    history = model.fit(X_train, Y_train, epochs=30, verbose=0, validation_split=0.2, callbacks=[early_stopping])\n",
        "    # Get the train and validation losses\n",
        "    train_loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    # Make predictions\n",
        "    Y_train_pred = model.predict(X_train)\n",
        "    Y_val_pred = model.predict(X_train[-int(0.2 * len(X_train)):])\n",
        "\n",
        "    # Calculate the mean absolute error\n",
        "    train_mae = mean_absolute_error(Y_train, Y_train_pred)\n",
        "    val_mae = mean_absolute_error(Y_train[-int(0.2 * len(Y_train)):], Y_val_pred)\n",
        "\n",
        "    print(f\"Location: {location}, Train MAE: {train_mae}, Validation MAE: {val_mae}\")\n",
        "\n",
        "    Y_test_missing_pred = model.predict(X_test)\n",
        "\n",
        "    for i, missing_index in enumerate(missing_indices):\n",
        "        start = missing_index + lookback\n",
        "        end = start + future\n",
        "        test_data_loc[start:end, 0] = Y_test_missing_pred[i]\n",
        "\n",
        "    # Inverse transform the test data to get real values\n",
        "    test_data_loc_real = scaler.inverse_transform(test_data_loc)\n",
        "\n",
        "    # Create a new DataFrame with real values\n",
        "    test_data_loc_real_df = pd.DataFrame(test_data_loc_real, columns=['PM2.5', 'tem', 'wind degree', 'wind velocity', 'precipitation', 'humidity'])\n",
        "\n",
        "    # Get the '지점' and '관측시점' columns from the original test data\n",
        "    test_data_loc_observation = sort_data.loc[sort_data['지점'] == location, ['지점', '관측시점']].reset_index(drop=True)\n",
        "\n",
        "    # Concatenate '지점' and '관측시점' columns with the test_data_loc_real_df DataFrame\n",
        "    test_data_loc_real_df = pd.concat([test_data_loc_observation, test_data_loc_real_df], axis=1)\n",
        "\n",
        "    # Append the test_data_loc_real_df to the all_test_data_real DataFrame\n",
        "    all_test_data_real = all_test_data_real.append(test_data_loc_real_df, ignore_index=True)    \n",
        "\n",
        "# Sort the DataFrame by '지점' and '관측시점'\n",
        "all_test_data_real = all_test_data_real.sort_values(by=['지점', '관측시점']).reset_index(drop=True)\n",
        "\n",
        "# Print the resulting DataFrame\n",
        "all_test_data_real.to_csv('/content/new/result_256_drop3.csv', index=False)\n",
        "\n",
        "all_test_data_real.head(100)\n",
        "\n",
        "result = all_test_data_real\n",
        "new_column = {'일시' : '관측시점'}\n",
        "result = result.rename(columns= new_column)\n",
        "result\n",
        "result.to_csv('/content/new/again.csv', index=False)\n",
        "result.head(50)\n",
        "\n",
        "os.chdir('/content/sample')\n",
        "all_files = glob.glob('*.csv')\n",
        "dfs = []\n",
        "for file in all_files:\n",
        "    df = pd.read_csv(file)\n",
        "    dfs.append(df)\n",
        "\n",
        "answer = pd.concat(dfs, ignore_index=True)\n",
        "new_column = {'측정소' : '지점'}\n",
        "answer = answer.rename(columns= new_column)\n",
        "answer['관측시점'] = answer['연도'].apply(convert_year) + '-' + answer['일시']\n",
        "answer\n",
        "\n",
        "# Merge the result DataFrame with the answer sheet\n",
        "final_data = answer.merge(result[['관측시점', '지점', 'PM2.5']], on=['관측시점', '지점'], how='left')\n",
        "final_data.drop(['PM2.5_x', '관측시점'], axis=1, inplace=True)\n",
        "final_data.rename(columns={'PM2.5_y': 'PM2.5'}, inplace=True)\n",
        "final_data.rename(columns={'지점': '측정소'}, inplace=True)\n",
        "final_data\n",
        "\n",
        "final_data.to_csv('/content/new/again.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# Download the pickle file\n",
        "files.download('model.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "S32DUjsn8sFO",
        "outputId": "b9bbe14b-36e1-4f55-b3cc-9920786384fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_572c2677-f4a0-4a84-a981-5e4200fa6c22\", \"model.pkl\", 9790319)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('/content/new/again.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-KxysEghbc-4",
        "outputId": "fe321cab-6953-4200-e5b2-3a97cb1fbb6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_903709ff-8d29-4ee1-ad8c-dc7ed18d74f8\", \"again.csv\", 3428118)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_data"
      ],
      "metadata": {
        "id": "3x89Arnzg35i",
        "outputId": "b5988610-91c3-472f-ee74-42da19a7b89e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         지점  PM2.5              관측시점    기온(°C)   풍향(deg)   풍속(m/s)  강수량(mm)  \\\n",
              "270074   공주  0.056  2000-01-01 00:00  0.173776  0.201944  0.023018      0.0   \n",
              "270075   공주  0.060  2000-01-01 01:00  0.176935  0.168611  0.030691      0.0   \n",
              "270076   공주  0.068  2000-01-01 02:00  0.180095  0.087222  0.033248      0.0   \n",
              "270077   공주  0.060  2000-01-01 03:00  0.178515  0.087222  0.025575      0.0   \n",
              "270078   공주  0.068  2000-01-01 04:00  0.164297  0.113889  0.020460      0.0   \n",
              "...     ...    ...               ...       ...       ...       ...      ...   \n",
              "568387  홍성읍  0.060  2003-12-31 19:00  0.273302  0.832222  0.086957      0.0   \n",
              "568388  홍성읍  0.052  2003-12-31 20:00  0.271722  0.831667  0.043478      0.0   \n",
              "568389  홍성읍  0.044  2003-12-31 21:00  0.268562  0.832500  0.066496      0.0   \n",
              "568390  홍성읍  0.052  2003-12-31 22:00  0.262243  0.866944  0.043478      0.0   \n",
              "568391  홍성읍  0.060  2003-12-31 23:00  0.257504  0.000000  0.000000      0.0   \n",
              "\n",
              "        습도(%)  \n",
              "270074  0.828  \n",
              "270075  0.831  \n",
              "270076  0.784  \n",
              "270077  0.745  \n",
              "270078  0.750  \n",
              "...       ...  \n",
              "568387  0.671  \n",
              "568388  0.692  \n",
              "568389  0.706  \n",
              "568390  0.725  \n",
              "568391  0.710  \n",
              "\n",
              "[570581 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70982d94-d8d0-4757-82f8-852aa9d39ce5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>지점</th>\n",
              "      <th>PM2.5</th>\n",
              "      <th>관측시점</th>\n",
              "      <th>기온(°C)</th>\n",
              "      <th>풍향(deg)</th>\n",
              "      <th>풍속(m/s)</th>\n",
              "      <th>강수량(mm)</th>\n",
              "      <th>습도(%)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>270074</th>\n",
              "      <td>공주</td>\n",
              "      <td>0.056</td>\n",
              "      <td>2000-01-01 00:00</td>\n",
              "      <td>0.173776</td>\n",
              "      <td>0.201944</td>\n",
              "      <td>0.023018</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270075</th>\n",
              "      <td>공주</td>\n",
              "      <td>0.060</td>\n",
              "      <td>2000-01-01 01:00</td>\n",
              "      <td>0.176935</td>\n",
              "      <td>0.168611</td>\n",
              "      <td>0.030691</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270076</th>\n",
              "      <td>공주</td>\n",
              "      <td>0.068</td>\n",
              "      <td>2000-01-01 02:00</td>\n",
              "      <td>0.180095</td>\n",
              "      <td>0.087222</td>\n",
              "      <td>0.033248</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270077</th>\n",
              "      <td>공주</td>\n",
              "      <td>0.060</td>\n",
              "      <td>2000-01-01 03:00</td>\n",
              "      <td>0.178515</td>\n",
              "      <td>0.087222</td>\n",
              "      <td>0.025575</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270078</th>\n",
              "      <td>공주</td>\n",
              "      <td>0.068</td>\n",
              "      <td>2000-01-01 04:00</td>\n",
              "      <td>0.164297</td>\n",
              "      <td>0.113889</td>\n",
              "      <td>0.020460</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568387</th>\n",
              "      <td>홍성읍</td>\n",
              "      <td>0.060</td>\n",
              "      <td>2003-12-31 19:00</td>\n",
              "      <td>0.273302</td>\n",
              "      <td>0.832222</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568388</th>\n",
              "      <td>홍성읍</td>\n",
              "      <td>0.052</td>\n",
              "      <td>2003-12-31 20:00</td>\n",
              "      <td>0.271722</td>\n",
              "      <td>0.831667</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568389</th>\n",
              "      <td>홍성읍</td>\n",
              "      <td>0.044</td>\n",
              "      <td>2003-12-31 21:00</td>\n",
              "      <td>0.268562</td>\n",
              "      <td>0.832500</td>\n",
              "      <td>0.066496</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568390</th>\n",
              "      <td>홍성읍</td>\n",
              "      <td>0.052</td>\n",
              "      <td>2003-12-31 22:00</td>\n",
              "      <td>0.262243</td>\n",
              "      <td>0.866944</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568391</th>\n",
              "      <td>홍성읍</td>\n",
              "      <td>0.060</td>\n",
              "      <td>2003-12-31 23:00</td>\n",
              "      <td>0.257504</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.710</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>570581 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70982d94-d8d0-4757-82f8-852aa9d39ce5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-70982d94-d8d0-4757-82f8-852aa9d39ce5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-70982d94-d8d0-4757-82f8-852aa9d39ce5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1HHjPgITqOs3nLJ3SkiOH49JXVM91mFgT",
      "authorship_tag": "ABX9TyO9xyFTk5v26UDz1ouQdPJj",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
